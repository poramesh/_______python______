Writing our first test


We identify a bug

Fortunately, there’s a little bug in the polls application for us to fix right away: the Question.was_published_recently() 
method returns True if the Question was published within the last day (which is correct) but also if the Question’s pub_date field is in the future (which certainly isn’t).

Confirm the bug by using the shell to check the method on a question whose date lies in the future:

$ python manage.py shell
>>> import datetime
>>> from django.utils import timezone
>>> # create a Question instance with pub_date 30 days in the future
>>> future_question = Question(pub_date=timezone.now() + datetime.timedelta(days=30))
>>> # was it published recently?
>>> future_question.was_published_recently()
True
Since things in the future are not ‘recent’, this is clearly wrong.



Create a test to expose the bug

What we’ve just done in the shell to test for the problem is exactly what we can do in an automated test, so let’s turn that into an automated test.
A conventional place for an application’s tests is in the application’s tests.py file; the testing system will automatically find tests in any file whose
name begins with test.
Put the following in the tests.py file in the polls application:

polls/tests.py

import datetime

from django.test import TestCase
from django.utils import timezone

from .models import Question


class QuestionModelTests(TestCase):
    def test_was_published_recently_with_future_question(self):
        """
        was_published_recently() returns False for questions whose pub_date
        is in the future.
        """
        time = timezone.now() + datetime.timedelta(days=30)
        future_question = Question(pub_date=time)
        self.assertIs(future_question.was_published_recently(), False)


Here we have created a django.test.TestCase subclass with a method that creates a Question instance with a pub_date in the future.
We then check the output of was_published_recently() - which ought to be False.


Running tests


In the terminal, we can run our test:

$ python manage.py test polls
and you’ll see something like:
Creating test database for alias 'default'...
System check identified no issues (0 silenced).
F
======================================================================
FAIL: test_was_published_recently_with_future_question (polls.tests.QuestionModelTests)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/path/to/djangotutorial/polls/tests.py", line 16, in test_was_published_recently_with_future_question
    self.assertIs(future_question.was_published_recently(), False)
AssertionError: True is not False

----------------------------------------------------------------------
Ran 1 test in 0.001s

FAILED (failures=1)
Destroying test database for alias 'default'...
Different error?

If instead you’re getting a NameError here, you may have missed a step in Part 2 where we added imports of datetime and timezone to polls/models.py. 
Copy the imports from that section, and try running your tests again.

What happened is this:
manage.py test polls looked for tests in the polls application
it found a subclass of the django.test.TestCase class
it created a special database for the purpose of testing
it looked for test methods - ones whose names begin with test
in test_was_published_recently_with_future_question it created a Question instance whose pub_date field is 30 days in the future

… and using the assertIs() method, it discovered that its was_published_recently() returns True, though we wanted it to return False

The test informs us which test failed and even the line on which the failure occurred.



Fixing the bug

We already know what the problem is: Question.was_published_recently() should return False if its pub_date is in the future. Amend 
the method in models.py, so that it will only return True if the date is also in the past:

polls/models.py

def was_published_recently(self):
    now = timezone.now()
    return now - datetime.timedelta(days=1) <= self.pub_date <= now

and run the test again:
Creating test database for alias 'default'...
System check identified no issues (0 silenced).

----------------------------------------------------------------------
Ran 1 test in 0.001s

OK
Destroying test database for alias 'default'...
After identifying a bug, we wrote a test that exposes it and corrected the bug in the code so our test passes.
Many other things might go wrong with our application in the future, but we can be sure that we won’t inadvertently reintroduce this bug, 
because running the test will warn us immediately. We can consider this little portion of the application pinned down safely forever.



More comprehensive tests

While we’re here, we can further pin down the was_published_recently() method; in fact, it would be positively embarrassing if in fixing one
bug we had introduced another.

Add two more test methods to the same class, to test the behavior of the method more comprehensively:

polls/tests.py

def test_was_published_recently_with_old_question(self):
    """
    was_published_recently() returns False for questions whose pub_date
    is older than 1 day.
    """
    time = timezone.now() - datetime.timedelta(days=1, seconds=1)
    old_question = Question(pub_date=time)
    self.assertIs(old_question.was_published_recently(), False)


def test_was_published_recently_with_recent_question(self):
    """
    was_published_recently() returns True for questions whose pub_date
    is within the last day.
    """
    time = timezone.now() - datetime.timedelta(hours=23, minutes=59, seconds=59)
    recent_question = Question(pub_date=time)
    self.assertIs(recent_question.was_published_recently(), True)

And now we have three tests that confirm that Question.was_published_recently() returns sensible values for past, recent, and future questions.
Again, polls is a minimal application, but however complex it grows in the future and whatever other code it interacts with, 
we now have some guarantee that the method we have written tests for will behave in expected ways.



****When you run:

python manage.py test

Here’s what happens:
Django checks settings and creates a test database like test_<your_db_name>.
Runs all migrations on the test DB.
Runs each test case in isolation with a transaction.
Rolls back after each test.
Deletes the test DB after all tests complete.

***


Test a view

The polls application is fairly undiscriminating: it will publish any question, including ones whose pub_date
field lies in the future. We should improve this. Setting a pub_date in the future should mean that
the Question is published at that moment, but invisible until then.

A test for a view

When we fixed the bug above, we wrote the test first and then the code to fix it. In fact that was an example of test-driven development,
but it doesn’t really matter in which order we do the work.
In our first test, we focused closely on the internal behavior of the code. For this test, we want to check its behavior as it would 
be experienced by a user through a web browser.
Before we try to fix anything, let’s have a look at the tools at our disposal.


The Django test client

Django provides a test Client to simulate a user interacting with the code at the view level. We can use it in tests.py or even in the shell.
We will start again with the shell, where we need to do a couple of things that won’t be necessary in tests.py. 
The first is to set up the test environment in the shell:

$ python manage.py shell
>>> from django.test.utils import setup_test_environment
>>> setup_test_environment()

setup_test_environment() installs a template renderer which will allow us to examine some additional attributes on responses such as 
response.context that otherwise wouldn’t be available. Note that this method does not set up a test database, so the following will
be run against the existing database and the output may differ slightly depending on what questions you already created. You might get unexpected results 
if your TIME_ZONE in settings.py isn’t correct. If you don’t remember setting it earlier, check it before continuing.

Next we need to import the test client class (later in tests.py we will use the django.test.TestCase class, which comes with its own client, so this won’t be required):

>>> from django.test import Client
>>> # create an instance of the client for our use
>>> client = Client()
With that ready, we can ask the client to do some work for us:

>>> # get a response from '/'
>>> response = client.get("/")
Not Found: /
>>> # we should expect a 404 from that address; if you instead see an
>>> # "Invalid HTTP_HOST header" error and a 400 response, you probably
>>> # omitted the setup_test_environment() call described earlier.
>>> response.status_code
404
>>> # on the other hand we should expect to find something at '/polls/'
>>> # we'll use 'reverse()' rather than a hardcoded URL
>>> from django.urls import reverse
>>> response = client.get(reverse("polls:index"))
>>> response.status_code
200
>>> response.content
b'\n    <ul>\n    \n        <li><a href="/polls/1/">What&#x27;s up?</a></li>\n    \n    </ul>\n\n'
>>> response.context["latest_question_list"]
<QuerySet [<Question: What's up?>]>




*********
herer it is not starting the development server (runserver is not involved at all).
Instead, Django is:
Simulating the entire request–response cycle internally, using the same machinery it uses when a browser
sends a request — but without starting a real web server or opening a port.

Client() is Django’s test client — it mocks an HTTP client.
When you call client.get("/"), it:
Constructs an internal HttpRequest object.
Sends it through Django's middleware and URL dispatcher.
Invokes the correct view function/class, just like a real request.
Gets the response (an HttpResponse).
Gives it back to you — without needing a browser or HTTP server.




Django goes through these steps:

Start with the project's main urls.py
Usually at: myproject/urls.py

Example:

urlpatterns = [
    path("polls/", include("polls.urls")),
    path("admin/", admin.site.urls),
]

This says:
Anything starting with /polls/ → check polls/urls.py
/admin/ → use admin views
/ by itself → no match unless something is registered explicitly at root

If you hit / and there is no path("", ...) defined, then Django says:
"I don’t know what to show at /, so I’ll return a 404 Not Found."

so in our example:
response = client.get("/")
Django checks urls.py
Sees no URL pattern matching /
Returns a 404

Which is why you got:
Not Found: /
response.status_code  #



How does this change with something like reverse("polls:index")?
When you do:
reverse("polls:index")
It looks up the URL name "polls:index" and finds the path it’s mapped to — like:
# polls/urls.py

app_name = "polls"

urlpatterns = [
    path("", views.IndexView.as_view(), name="index"),
]
So "polls:index" becomes /polls/, and now:
client.get(reverse("polls:index"))

means:
Simulate a GET request to /polls/
Which Django knows how to handle (because of your URL config), so it sends the request to the appropriate view.
*********




Improving our view

The list of polls shows polls that aren’t published yet (i.e. those that have a pub_date in the future). Let’s fix that.

In Tutorial 4 we introduced a class-based view, based on ListView:

polls/views.py

class IndexView(generic.ListView):
    template_name = "polls/index.html"
    context_object_name = "latest_question_list"

    def get_queryset(self):
        """Return the last five published questions."""
        return Question.objects.order_by("-pub_date")[:5]

We need to amend the get_queryset() method and change it so that it also checks the date by comparing it with timezone.now().

First we need to add an import:

polls/views.py

from django.utils import timezone
and then we must amend the get_queryset method like so:

polls/views.py
def get_queryset(self):
    """
    Return the last five published questions (not including those set to be
    published in the future).
    """
    return Question.objects.filter(pub_date__lte=timezone.now()).order_by("-pub_date")[
        :5
    ]

Question.objects.filter(pub_date__lte=timezone.now()) returns a queryset containing Questions whose pub_date is less
than or equal to - that is, earlier than or equal to - timezone.now().




****
In Django’s order_by():
"pub_date" → orders by pub_date in ascending order (oldest → newest).
"-pub_date" → orders by pub_date in descending order (newest → oldest).

| Lookup        | Meaning                                  |
| ------------- | --------------- ------------------------ |
| pub_date__lt  | pub_date < value                         |
| pub_date__lte | pub_date ≤ value (less than or equal)    |
| pub_date__gt  | pub_date > value                         |
| pub_date__gte | pub_date ≥ value (greater than or equal) |
| pub_date      | pub_date == value                        |


***



Testing our new view

Now you can satisfy yourself that this behaves as expected by firing up runserver, loading the site in your browser, creating a few
Question entries with dates in the past and future, and checking that only those that have been published are listed. You don’t want 
to have to do that every single time you make any change that might affect this - so let’s also create a test, based on our shell session above.

Add the following to polls/tests.py:

polls/tests.py

from django.urls import reverse
and we’ll create a shortcut function to create questions as well as a new test class:

polls/tests.py

def create_question(question_text, days):
    """
    Create a question with the given `question_text` and published the
    given number of `days` offset to now (negative for questions published
    in the past, positive for questions that have yet to be published).
    """
    time = timezone.now() + datetime.timedelta(days=days)
    return Question.objects.create(question_text=question_text, pub_date=time)


class QuestionIndexViewTests(TestCase):
    def test_no_questions(self):
        """
        If no questions exist, an appropriate message is displayed.
        """
        response = self.client.get(reverse("polls:index"))
        self.assertEqual(response.status_code, 200)
        self.assertContains(response, "No polls are available.")
        self.assertQuerySetEqual(response.context["latest_question_list"], [])

    def test_past_question(self):
        """
        Questions with a pub_date in the past are displayed on the
        index page.
        """
        question = create_question(question_text="Past question.", days=-30)
        response = self.client.get(reverse("polls:index"))
        self.assertQuerySetEqual(
            response.context["latest_question_list"],
            [question],
        )

    def test_future_question(self):
        """
        Questions with a pub_date in the future aren't displayed on
        the index page.
        """
        create_question(question_text="Future question.", days=30)
        response = self.client.get(reverse("polls:index"))
        self.assertContains(response, "No polls are available.")
        self.assertQuerySetEqual(response.context["latest_question_list"], [])

    def test_future_question_and_past_question(self):
        """
        Even if both past and future questions exist, only past questions
        are displayed.
        """
        question = create_question(question_text="Past question.", days=-30)
        create_question(question_text="Future question.", days=30)
        response = self.client.get(reverse("polls:index"))
        self.assertQuerySetEqual(
            response.context["latest_question_list"],
            [question],
        )

    def test_two_past_questions(self):
        """
        The questions index page may display multiple questions.
        """
        question1 = create_question(question_text="Past question 1.", days=-30)
        question2 = create_question(question_text="Past question 2.", days=-5)
        response = self.client.get(reverse("polls:index"))
        self.assertQuerySetEqual(
            response.context["latest_question_list"],
            [question2, question1],
        )



***

When used in a test
If this is inside a Django test class (TestCase), then:
Django creates a temporary test database before the test runs.
The question is saved to that temporary database.
After the test finishes, the test DB is destroyed — so your real data is unaffected.


and when i did this 
    <p>{{latest_question_list }}</p>

it printed
<QuerySet [<Question: alright changed>]>

in the webpafe


Now response.context["latest_question_list"] returns: <QuerySet [<Question: Past Question>]>
[question] is: [<Question: Past Question>]

***

>Let’s look at some of these more closely.
>First is a question shortcut function, create_question, to take some repetition out of the process of creating questions.
>test_no_questions doesn’t create any questions, but checks the message: “No polls are available.” and verifies the latest_question_list is empty. 
Note that the django.test.TestCase class provides some additional assertion methods. In these examples, we use assertContains() and assertQuerySetEqual().
>In test_past_question, we create a question and verify that it appears in the list.

In test_future_question, we create a question with a pub_date in the future. The database is reset for each test method, so the first question is no 
longer there, and so again the index shouldn’t have any questions in it.

And so on. In effect, we are using the tests to tell a story of admin input and user experience on the site, and checking that at every state and for
every new change in the state of the system, the expected results are published.



Testing the DetailView

What we have works well; however, even though future questions don’t appear in the index, users can still reach them if 
they know or guess the right URL. So we need to add a similar constraint to DetailView:


polls/views.py

class DetailView(generic.DetailView):
    ...

    def get_queryset(self):
        """
        Excludes any questions that aren't published yet.
        """
        return Question.objects.filter(pub_date__lte=timezone.now())


We should then add some tests, to check that a Question whose pub_date is in the past can be displayed, and that one with a pub_date in the future is not:

polls/tests.py

class QuestionDetailViewTests(TestCase):
    def test_future_question(self):
        """
        The detail view of a question with a pub_date in the future
        returns a 404 not found.
        """
        future_question = create_question(question_text="Future question.", days=5)
        url = reverse("polls:detail", args=(future_question.id,))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 404)

    def test_past_question(self):
        """
        The detail view of a question with a pub_date in the past
        displays the question's text.
        """
        past_question = create_question(question_text="Past Question.", days=-5)
        url = reverse("polls:detail", args=(past_question.id,))
        response = self.client.get(url)
        self.assertContains(response, past_question.question_text)






Ideas for more tests

We ought to add a similar get_queryset method to ResultsView and create a new test class for that view. It’ll be very similar to 
what we have just created; in fact there will be a lot of repetition.

We could also improve our application in other ways, adding tests along the way. For example, it’s pointless that a Question with
no related Choice can be published on the site. So, our views could check for this, and exclude such Question objects. Our tests
would create a Question without a Choice, and then test that it’s not published, as well as create a similar Question
with at least one Choice, and test that it is published.

Perhaps logged-in admin users should be allowed to see unpublished Question entries, but not ordinary visitors. 
Again: whatever needs to be added to the software to accomplish this should be accompanied by a test, whether you write 
the test first and then make the code pass the test, or work out the logic in your code first and then write a test to prove it.

At a certain point you are bound to look at your tests and wonder whether your code is suffering from test bloat, which brings us to:



When testing, more is better

It might seem that our tests are growing out of control. At this rate there will soon be more code in our tests than in our application, and
the repetition is unaesthetic, compared to the elegant conciseness of the rest of our code.

It doesn’t matter. Let them grow. For the most part, you can write a test once and then forget about it. It will continue performing its 
useful function as you continue to develop your program.

Sometimes tests will need to be updated. Suppose that we amend our views so that only Question entries with associated Choice instances 
are published. In that case, many of our existing tests will fail - telling us exactly which tests need to be amended to bring them up
to date, so to that extent tests help look after themselves.

At worst, as you continue developing, you might find that you have some tests that are now redundant. Even that’s not a problem; in testing redundancy is a good thing.

As long as your tests are sensibly arranged, they won’t become unmanageable. Good rules-of-thumb include having:
a separate TestClass for each model or view
a separate test method for each set of conditions you want to test
test method names that describe their function



Further testing

This tutorial only introduces some of the basics of testing. There’s a great deal more you can do, and a number of very useful tools 
at your disposal to achieve some very clever things.

For example, while our tests here have covered some of the internal logic of a model and the way our views publish information, you can
use an “in-browser” framework such as Selenium to test the way your HTML actually renders in a browser. These tools allow you to check not
just the behavior of your Django code, but also, for example, of your JavaScript. It’s quite something to see the tests launch a browser,
and start interacting with your site, as if a human being were driving it! Django includes LiveServerTestCase to facilitate integration with tools like Selenium.

If you have a complex application, you may want to run tests automatically with every commit for the purposes of continuous integration, 
so that quality control is itself - at least partially - automated.

A good way to spot untested parts of your application is to check code coverage. This also helps identify fragile or even dead code. If 
you can’t test a piece of code, it usually means that code should be refactored or removed. Coverage 
will help to identify dead code. See Integration with coverage.py for details.

Testing in Django has comprehensive information about testing.






********************

I ASKED THE CHATGPT TO EXPLAIN THE ABOVE CAUSE I DONT KNOW WHY I COULDNT GET PAST A LINE BUT CHATGPT EXPLANTION MADE ME UNDERTAND IT BETTER


1. More Test Coverage for Views Like ResultsView

"We ought to add a similar get_queryset() method to ResultsView and create a new test class for that view."
Explanation: If you’ve added a custom get_queryset() method in your IndexView to filter questions 
(e.g., exclude future-dated or no-choice questions), you should do the same in other views like ResultsView.

Next step: Create a new test class, e.g., ResultsViewTests, and test things like:
It doesn’t show unpublished questions.
It doesn't show questions with no choices.
Only valid (published and answerable) questions appear.

2. Handling Questions Without Choices
"It’s pointless that a Question with no related Choice can be published on the site."
Idea: If a question has no choices, users can’t vote. So such questions should be excluded from published views.
Code implication: In your get_queryset() method, you can filter for:
Question.objects.annotate(num_choices=Count('choice')).filter(num_choices__gt=0)

Test idea: Write tests that:
Create a Question with no choices → assert that it’s not in the list view.
Create a Question with at least one choice → assert that it is in the list view.

3. Role-Based Access: Admin vs Normal User
"Perhaps logged-in admin users should be allowed to see unpublished Question entries..."
Feature idea: Show draft or future questions only to admins.

How?
Use request.user.is_staff or request.user.is_authenticated in your view logic.

Write tests for:
Normal users can’t see future or draft questions.
Admin users can.

4. Test Bloat vs Test Value
"At this rate there will soon be more code in our tests than in our application..."

Important insight: That’s okay.

Tests protect your app.
More tests → more confidence as you refactor, optimize, or expand features.
Even if you change your app’s logic (e.g., to hide questions with no choices), tests will fail appropriately, telling you what needs updating.
Redundant tests are fine — they act as safety nets.

5. Best Practices Suggested
One TestClass per model or view
QuestionModelTests
IndexViewTests
ResultsViewTests, etc.
One method per condition
test_question_with_future_pub_date_is_not_shown()
Descriptive test method names
Makes your test suite self-documenting.

6. Advanced Testing Tools
"You can use an 'in-browser' framework such as Selenium..."
Selenium: Automates browser actions. Useful for:
Testing how HTML and JavaScript work together.
Testing user flows like voting, logging in, etc.
LiveServerTestCase: Django test class that starts a live server for such end-to-end tests.

7. Continuous Integration (CI)
"You may want to run tests automatically with every commit..."
Tools like GitHub Actions, GitLab CI, Travis CI, Jenkins, etc., can:
Run tests on every push or pull request.
Prevent bad code from being merged.

8. Code Coverage
"Check code coverage. This helps identify fragile or even dead code."

Use coverage.py:
coverage run manage.py test
coverage report
coverage html  # For a browsable report

Helps find:
Untested code
Code that’s never used (dead code)
Areas needing refactoring






Redundancy means repeated or no longer strictly necessary.

For example:
You might write several different tests that all check whether future questions are excluded from views.
Later, you may update the logic in one place (like get_queryset()), and all those tests still pass, even though they’re testing similar things.

In most areas of coding, redundancy is bad (it causes clutter and confusion). But in testing, redundancy can be good:
It acts as a safety net.
If one test misses a bug, another might catch it.
Even if you refactor or delete a piece of code, your redundant tests will let you know what still needs to work.


*******************
